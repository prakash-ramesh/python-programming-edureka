{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dITKFbWGAmLa"
      },
      "source": [
        "## Demo 3 - Scraping Book Titles Using Scrapy\n",
        "\n",
        "In this demo, you will use Scrapy to fetch book titles from books.toscrape.com."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZOJkkN1AmLf"
      },
      "source": [
        "<h3>1. Installing scrapy and importing required modules"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scrapy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1ftxg39Aw-N",
        "outputId": "358ba9f1-7447-4c65-9fe1-60e9b0aaba4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scrapy in /usr/local/lib/python3.7/dist-packages (2.6.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from scrapy) (57.4.0)\n",
            "Requirement already satisfied: PyDispatcher>=2.0.5 in /usr/local/lib/python3.7/dist-packages (from scrapy) (2.0.5)\n",
            "Requirement already satisfied: pyOpenSSL>=16.2.0 in /usr/local/lib/python3.7/dist-packages (from scrapy) (22.0.0)\n",
            "Requirement already satisfied: protego>=0.1.15 in /usr/local/lib/python3.7/dist-packages (from scrapy) (0.2.1)\n",
            "Requirement already satisfied: itemadapter>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from scrapy) (0.7.0)\n",
            "Requirement already satisfied: Twisted>=17.9.0 in /usr/local/lib/python3.7/dist-packages (from scrapy) (22.4.0)\n",
            "Requirement already satisfied: cssselect>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from scrapy) (1.1.0)\n",
            "Requirement already satisfied: zope.interface>=4.1.3 in /usr/local/lib/python3.7/dist-packages (from scrapy) (5.4.0)\n",
            "Requirement already satisfied: cryptography>=2.0 in /usr/local/lib/python3.7/dist-packages (from scrapy) (37.0.4)\n",
            "Requirement already satisfied: parsel>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from scrapy) (1.6.0)\n",
            "Requirement already satisfied: w3lib>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from scrapy) (2.0.1)\n",
            "Requirement already satisfied: itemloaders>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scrapy) (1.0.4)\n",
            "Requirement already satisfied: tldextract in /usr/local/lib/python3.7/dist-packages (from scrapy) (3.3.1)\n",
            "Requirement already satisfied: lxml>=3.5.0 in /usr/local/lib/python3.7/dist-packages (from scrapy) (4.9.1)\n",
            "Requirement already satisfied: queuelib>=1.4.2 in /usr/local/lib/python3.7/dist-packages (from scrapy) (1.6.2)\n",
            "Requirement already satisfied: service-identity>=16.0.0 in /usr/local/lib/python3.7/dist-packages (from scrapy) (21.1.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.0->scrapy) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.0->scrapy) (2.21)\n",
            "Requirement already satisfied: jmespath>=0.9.5 in /usr/local/lib/python3.7/dist-packages (from itemloaders>=1.0.1->scrapy) (1.0.1)\n",
            "Requirement already satisfied: six>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from parsel>=1.5.0->scrapy) (1.15.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.7/dist-packages (from service-identity>=16.0.0->scrapy) (22.1.0)\n",
            "Requirement already satisfied: pyasn1 in /usr/local/lib/python3.7/dist-packages (from service-identity>=16.0.0->scrapy) (0.4.8)\n",
            "Requirement already satisfied: pyasn1-modules in /usr/local/lib/python3.7/dist-packages (from service-identity>=16.0.0->scrapy) (0.2.8)\n",
            "Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from Twisted>=17.9.0->scrapy) (4.1.1)\n",
            "Requirement already satisfied: incremental>=21.3.0 in /usr/local/lib/python3.7/dist-packages (from Twisted>=17.9.0->scrapy) (21.3.0)\n",
            "Requirement already satisfied: constantly>=15.1 in /usr/local/lib/python3.7/dist-packages (from Twisted>=17.9.0->scrapy) (15.1.0)\n",
            "Requirement already satisfied: hyperlink>=17.1.1 in /usr/local/lib/python3.7/dist-packages (from Twisted>=17.9.0->scrapy) (21.0.0)\n",
            "Requirement already satisfied: Automat>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from Twisted>=17.9.0->scrapy) (20.2.0)\n",
            "Requirement already satisfied: idna>=2.5 in /usr/local/lib/python3.7/dist-packages (from hyperlink>=17.1.1->Twisted>=17.9.0->scrapy) (2.10)\n",
            "Requirement already satisfied: requests>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from tldextract->scrapy) (2.23.0)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from tldextract->scrapy) (3.8.0)\n",
            "Requirement already satisfied: requests-file>=1.4 in /usr/local/lib/python3.7/dist-packages (from tldextract->scrapy) (1.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->tldextract->scrapy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->tldextract->scrapy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->tldextract->scrapy) (2022.6.15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86D83uQHAmLg"
      },
      "outputs": [],
      "source": [
        "import scrapy\n",
        "from scrapy.crawler import CrawlerRunner # To Run our spider"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-S0kLCXAmLi"
      },
      "source": [
        "<h3>2. Setting up crochet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lYmt52MAmLj"
      },
      "source": [
        "<h5>To run spiders smoothly scrapy uses twisted library internally. But the problem is the twisted reactor can only be instantiated once. Therefore, crochet is used so that we can test our spider easily."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install crochet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbZ3_DRaBWts",
        "outputId": "21bb0c0b-0036-4d3f-c8ce-db74ae618c01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: crochet in /usr/local/lib/python3.7/dist-packages (2.0.0)\n",
            "Requirement already satisfied: Twisted>=16.0 in /usr/local/lib/python3.7/dist-packages (from crochet) (22.4.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.7/dist-packages (from crochet) (1.14.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from Twisted>=16.0->crochet) (4.1.1)\n",
            "Requirement already satisfied: Automat>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from Twisted>=16.0->crochet) (20.2.0)\n",
            "Requirement already satisfied: zope.interface>=4.4.2 in /usr/local/lib/python3.7/dist-packages (from Twisted>=16.0->crochet) (5.4.0)\n",
            "Requirement already satisfied: incremental>=21.3.0 in /usr/local/lib/python3.7/dist-packages (from Twisted>=16.0->crochet) (21.3.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from Twisted>=16.0->crochet) (22.1.0)\n",
            "Requirement already satisfied: hyperlink>=17.1.1 in /usr/local/lib/python3.7/dist-packages (from Twisted>=16.0->crochet) (21.0.0)\n",
            "Requirement already satisfied: constantly>=15.1 in /usr/local/lib/python3.7/dist-packages (from Twisted>=16.0->crochet) (15.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from Automat>=0.8.0->Twisted>=16.0->crochet) (1.15.0)\n",
            "Requirement already satisfied: idna>=2.5 in /usr/local/lib/python3.7/dist-packages (from hyperlink>=17.1.1->Twisted>=16.0->crochet) (2.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from zope.interface>=4.4.2->Twisted>=16.0->crochet) (57.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1os11MiXAmLk"
      },
      "outputs": [],
      "source": [
        "import crochet\n",
        "crochet.setup()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KpTSKmcAmLk"
      },
      "source": [
        "<h3>3. Inspecting the webpage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVNIL8mBAmLl"
      },
      "source": [
        "- Goto http://books.toscrape.com\n",
        "- Inspect the first title of the book"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkR1ipnRAmLn"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2PVkgxNAmLp"
      },
      "source": [
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAp6yxNfAmLq"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHzyq-CaAmLr"
      },
      "source": [
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2iHMbikAmLr"
      },
      "source": [
        "<h3>4. Building the spider"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOHZ8xekAmLs"
      },
      "outputs": [],
      "source": [
        "class BookSpider(scrapy.Spider):\n",
        "    name='BookSpider' # used to invoke spider\n",
        "    \n",
        "    #Used to start the requests\n",
        "    start_urls=['http://books.toscrape.com/catalogue/page-1.html',\n",
        "         'http://books.toscrape.com/catalogue/page-2.html',\n",
        "         'http://books.toscrape.com/catalogue/page-3.html']\n",
        "\n",
        "    ''' \n",
        "    Invoked by scrapy engine for every url\n",
        "    Here we will use selectors to scrap the website\n",
        "    '''\n",
        "    def parse(self,response):\n",
        "        book_list=response.css('article.product_pod>h3>a::attr(title)').getall()\n",
        "        \n",
        "        for i in book_list:\n",
        "            print(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aP4hn5zpAmLs"
      },
      "source": [
        "<h3>5. Crawling with spider"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-bS5UL1AmLt"
      },
      "source": [
        "<h6>Running the spider using CrawlRunner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsHfA349AmLt",
        "outputId": "e3e9d03e-8c8e-431c-b792-c9b0f0668066"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Deferred at 0x7f8672f182d0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "process = CrawlerRunner({\n",
        "    'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)',\n",
        "})\n",
        "process.crawl(BookSpider)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1dJxaO3AmLv"
      },
      "source": [
        "##### Conclusion: This code demonstrate how to fetch the data using Scrapy."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "1906_m8_demo2_Scraping_Book_Titles_Using_Scrapy_v1.0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}